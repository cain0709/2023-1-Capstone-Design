{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xD-cPv8V_uq2"
   },
   "source": [
    "Base Question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 1263,
     "status": "ok",
     "timestamp": 1679451663148,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "mUA0jYilAPnY",
    "outputId": "5f66c721-fc10-43fb-9bcf-4590de7cc0fc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' please make code 데이터셋 based on 인공지능 모델, \\n    using python. Plus, print F1 score and accuracy score. \\n    And also add model extraction code, extension is .pth.'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' please make code 데이터셋 based on 인공지능 모델, \n",
    "    using python. Plus, print F1 score and accuracy score. \n",
    "    And also add model extraction code, extension is .pth.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "executionInfo": {
     "elapsed": 29,
     "status": "ok",
     "timestamp": 1679451664828,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "RYXiXOJq_qPX",
    "outputId": "df14f78a-687d-4b10-cd59-18988c270edc"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "' please make code datasets.load_iris() based on RandomForestClassifier model, \\n    using python. Plus, print F1 score and accuracy score. \\n    And also add model extraction code, extension is .pth.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''' please make code datasets.load_iris() based on RandomForestClassifier model, \n",
    "    using python. Plus, print F1 score and accuracy score. \n",
    "    And also add model extraction code, extension is .pth.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2209,
     "status": "ok",
     "timestamp": 1679465883502,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "m4lTyJMt_t4K",
    "outputId": "f78c0cb4-2c54-44a6-f529-fce9abe5532b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.86\n",
      "Accuracy score: 0.76\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.7 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Fit a random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# Print the F1 score and accuracy score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"F1 score: {:.2f}\".format(f1))\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy))\n",
    "\n",
    "# Save the trained model\n",
    "#joblib.dump(clf, 'model.pth')\n",
    "\n",
    "# In this code, we first load the Iris dataset using the load_iris() function from sklearn.datasets. \n",
    "# We then split the dataset into training and testing sets, with 70% of the data used for training and 30% used for testing.\n",
    "# Next, we fit a RandomForestClassifier to the training data and use it to predict on the test set. \n",
    "# We then print the F1 score and accuracy score using f1_score() and accuracy_score() from sklearn.metrics.\n",
    "# Finally, we save the trained model using the joblib.dump() function with the file extension .pth.\n",
    "# Note that you may need to install joblib if you haven't already done so by running !pip install joblib."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HNTRmnbJHJjq"
   },
   "source": [
    "Personal Code Full (RFC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rihM7dCp_t81"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn.datasets as datasets\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o-1YBPx5_uC-"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "iris = datasets.load_iris()\n",
    "#EPOCH = 50\n",
    "#LR = 1e-3\n",
    "#BS = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MCX_taN2EuT2"
   },
   "outputs": [],
   "source": [
    "def seperate_x_y(df):\n",
    "    train_y = df['target']\n",
    "    train_x = df.drop('target', axis=1)\n",
    "    return train_x, train_y\n",
    "def make_df(data):\n",
    "    df = pd.DataFrame(data.data, columns = data.feature_names)\n",
    "    df['target'] = data.target\n",
    "    return df\n",
    "def return_shape(df): # return dataframe shape dim-0, dim-1 int data type\n",
    "    return df.shape[0], df.shape[1]\n",
    "\n",
    "def check_nan(df): #return nan check result boolean data type\n",
    "    nan_check = df.isnull().sum().tolist()\n",
    "    flag = False\n",
    "    for value in nan_check:\n",
    "        if value !=0:\n",
    "            flag = True\n",
    "            break\n",
    "    return flag\n",
    "#https://gibles-deepmind.tistory.com/m/138 -> whether variable is numeric or categorical\n",
    "def column_type_check(df):\n",
    "    numeric_col = df._get_numeric_data().columns.tolist()\n",
    "    categorical_col = list(set(df.columns) - set(numeric_col))\n",
    "\n",
    "    return numeric_col, categorical_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 24,
     "status": "ok",
     "timestamp": 1679465913878,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "jZiD3fcHEuYN",
    "outputId": "5a51a035-6274-47b6-a9ca-6db57da83c32"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-02aae05e-dd44-4f1e-8760-9733ba65af25\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 5 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-02aae05e-dd44-4f1e-8760-9733ba65af25')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-02aae05e-dd44-4f1e-8760-9733ba65af25 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-02aae05e-dd44-4f1e-8760-9733ba65af25');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "     sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                  5.1               3.5                1.4               0.2   \n",
       "1                  4.9               3.0                1.4               0.2   \n",
       "2                  4.7               3.2                1.3               0.2   \n",
       "3                  4.6               3.1                1.5               0.2   \n",
       "4                  5.0               3.6                1.4               0.2   \n",
       "..                 ...               ...                ...               ...   \n",
       "145                6.7               3.0                5.2               2.3   \n",
       "146                6.3               2.5                5.0               1.9   \n",
       "147                6.5               3.0                5.2               2.0   \n",
       "148                6.2               3.4                5.4               2.3   \n",
       "149                5.9               3.0                5.1               1.8   \n",
       "\n",
       "     target  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "..      ...  \n",
       "145       2  \n",
       "146       2  \n",
       "147       2  \n",
       "148       2  \n",
       "149       2  \n",
       "\n",
       "[150 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris_df = make_df(iris)\n",
    "iris_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 321,
     "status": "ok",
     "timestamp": 1679465927864,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "4aASIz5AE2LI",
    "outputId": "cdeb48a7-20d2-4898-a100-7dfe256dc64a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame shape : (150, 5)\n",
      "DataFrame has nan ? : False\n",
      "Numeric_col\n",
      "['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)', 'target']\n",
      "Categorical_col\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "row_cnt, col_cnt = return_shape(iris_df)\n",
    "nan_flag = check_nan(iris_df)\n",
    "numeric_col, categorical_col = column_type_check(iris_df)\n",
    "\n",
    "print(\"DataFrame shape : (\" + str(row_cnt) + \", \" + str(col_cnt)+\")\")\n",
    "print(\"DataFrame has nan ? : \" +str(nan_flag))\n",
    "print(\"Numeric_col\")\n",
    "print(numeric_col)\n",
    "print(\"Categorical_col\")\n",
    "print(categorical_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "executionInfo": {
     "elapsed": 359,
     "status": "error",
     "timestamp": 1679558253405,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "GgEYcvIxE2Ss",
    "outputId": "a99a2408-62a9-41c8-9b77-a4fe1b4c7850"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0e2afb879f9d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseperate_x_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miris_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSEED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Train size : \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation size: \"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'seperate_x_y' is not defined"
     ]
    }
   ],
   "source": [
    "train_x, train_y = seperate_x_y(iris_df)\n",
    "\n",
    "train_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2, random_state=SEED, shuffle=True, stratify=train_y)\n",
    "print(\"Train size : \" +str(train_x.shape))\n",
    "print(\"Validation size: \" +str(val_x.shape))\n",
    "\n",
    "\n",
    "n_list = [i for i in range(10, 105, 5)]\n",
    "best_n = 0\n",
    "best_f1 = 0\n",
    "for n in n_list:\n",
    "    rf = RandomForestClassifier(n_estimators = n, criterion = 'entropy', random_state=SEED)\n",
    "    rf.fit(train_x, train_y)\n",
    "    pred = rf.predict(val_x)\n",
    "    f1 = f1_score(val_y, pred, average='macro')\n",
    "    if f1 > best_f1:\n",
    "        best_n = n\n",
    "        best_f1 = f1\n",
    "\n",
    "rf_best = RandomForestClassifier(n_estimators = best_n, criterion = 'entropy', random_state=SEED)\n",
    "rf_best.fit(train_x, train_y)\n",
    "pred = rf_best.predict(val_x)\n",
    "\n",
    "print(\"best_n : \"+ str(best_n))\n",
    "print(\"F1 score : \" + str(f1_score(val_y, pred, average='macro')))\n",
    "print(\"Accuracy score : \" + str(accuracy_score(val_y, pred)))\n",
    "print(\"confustion matrix\")\n",
    "print(confusion_matrix(val_y, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hYM1UCWlHZb2"
   },
   "source": [
    "If Only Preprocessing (no dramatic change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 26,
     "status": "ok",
     "timestamp": 1679465985063,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "d7DVUUW7He2-",
    "outputId": "1b0e0464-d147-4b1c-cb78-b23c9c7cad34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.85\n",
      "Accuracy score: 0.73\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train = seperate_x_y(iris_df)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train ,y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Fit a random forest classifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "pred = clf.predict(X_test)\n",
    "\n",
    "# Print the F1 score and accuracy score\n",
    "f1 = f1_score(y_test, pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, pred)\n",
    "print(\"F1 score: {:.2f}\".format(f1))\n",
    "print(\"Accuracy score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 144702,
     "status": "ok",
     "timestamp": 1679452407425,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "8JcStgL6Ika7",
    "outputId": "e4a563b1-390e-4a4c-c7e3-596aca214c8d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1 score: 0.85\n",
      "Best accuracy score: 0.73\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.7 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the hyperparameter grid for the random forest classifier\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a random forest classifier and use grid search to find the best hyperparameters\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on the test set using the best estimator found by grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Print the best F1 score and accuracy score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best F1 score: {:.2f}\".format(f1))\n",
    "print(\"Best accuracy score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 108963,
     "status": "ok",
     "timestamp": 1679466125768,
     "user": {
      "displayName": "우영범",
      "userId": "10570956977622638449"
     },
     "user_tz": -540
    },
    "id": "3LNatTxiIkhf",
    "outputId": "852dfdf5-b790-45c1-995e-11bf5b1609a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 4, 'min_samples_split': 2, 'n_estimators': 50}\n",
      "Best F1 score: 0.87\n",
      "Best accuracy score: 0.77\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import joblib\n",
    "\n",
    "# Load iris dataset\n",
    "X_train, y_train = seperate_x_y(iris_df)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_size = int(0.8 * len(X))\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n",
    "\n",
    "# Define the hyperparameter grid for the random forest classifier\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 150],\n",
    "    'max_depth': [3, 5, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Create a random forest classifier and use grid search to find the best hyperparameters\n",
    "clf = RandomForestClassifier(random_state=42)\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid, cv=5, scoring='f1_weighted')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best parameters:\", grid_search.best_params_)\n",
    "\n",
    "# Predict on the test set using the best estimator found by grid search\n",
    "best_clf = grid_search.best_estimator_\n",
    "y_pred = best_clf.predict(X_test)\n",
    "\n",
    "# Print the best F1 score and accuracy score\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Best F1 score: {:.2f}\".format(f1))\n",
    "print(\"Best accuracy score: {:.2f}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gq_E1Nb3UQY-"
   },
   "source": [
    "Plus Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ommmPgheUS6t"
   },
   "outputs": [],
   "source": [
    "''' Please make code datasets.load_iris() based on RandomForestClassifier model, using python. \n",
    " Plus, I want to decide train_test_split(train_x, train_y, test_size = 0.2, random_state=42, shuffle=True, stratify=train_y) \n",
    " and print best F1 score and best accuracy score. \n",
    " And also add model extraction code, extension is .pth. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Z1FvbHoUTqe"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42, shuffle=True, stratify=iris.target)\n",
    "\n",
    "# create a random forest classifier model\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 200],\n",
    "    'max_depth': [None, 5, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4]\n",
    "}\n",
    "\n",
    "# perform a grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(rfc, param_grid, cv=5)\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# use the best hyperparameters to create a new random forest classifier model\n",
    "best_rfc = grid_search.best_estimator_\n",
    "\n",
    "# train the model on the training data\n",
    "best_rfc.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the testing data\n",
    "predictions = best_rfc.predict(test_x)\n",
    "\n",
    "# calculate the F1 score and accuracy score\n",
    "f1 = f1_score(test_y, predictions, average='macro')\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "\n",
    "print('Best F1 Score: {:.2f}'.format(f1))\n",
    "print('Best Accuracy Score: {:.2f}'.format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdivpijpUXhd"
   },
   "source": [
    "Plus Everything 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EUtSczq7Ued9"
   },
   "outputs": [],
   "source": [
    "''' Please make code datasets.load_iris() based on SupportVectorMachine model, using python. \n",
    "Plus, I want to decide train_test_split(train_x, train_y, test_size = 0.2, random_state=42, shuffle=True, stratify=train_y) \n",
    "and print best F1 score and best accuracy score. And also add model extraction code, extension is .pth. '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dGjNoOA9UeuE"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import joblib\n",
    "\n",
    "# load the iris dataset\n",
    "iris = load_iris()\n",
    "\n",
    "# split the data into training and testing sets\n",
    "train_x, test_x, train_y, test_y = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42, shuffle=True, stratify=iris.target)\n",
    "\n",
    "# create a support vector machine model\n",
    "svm = SVC()\n",
    "\n",
    "# define the parameter grid to search over\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'degree': [2, 3, 4],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# perform a grid search with cross-validation to find the best hyperparameters\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "grid_search.fit(train_x, train_y)\n",
    "\n",
    "# use the best hyperparameters to create a new support vector machine model\n",
    "best_svm = grid_search.best_estimator_\n",
    "\n",
    "# train the model on the training data\n",
    "best_svm.fit(train_x, train_y)\n",
    "\n",
    "# make predictions on the testing data\n",
    "predictions = best_svm.predict(test_x)\n",
    "\n",
    "# calculate the F1 score and accuracy score\n",
    "f1 = f1_score(test_y, predictions, average='macro')\n",
    "accuracy = accuracy_score(test_y, predictions)\n",
    "\n",
    "print('Best F1 Score: {:.2f}'.format(f1))\n",
    "print('Best Accuracy Score: {:.2f}'.format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOHyy4x+5KboKC5JAbaYWjp",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
